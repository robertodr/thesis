% mainfile: ../RobertoDiRemigioPhDThesis.tex
\chapter{Continuum solvation models}\label{ch:CSM}

\begin{itemize}
    \item why and how continuum solvation models
    \item derivation of \acs{IEF}-\acs{PCM}, importance of Green's
      functions.
    \item \ac{BEM} and wavelet \acs{BEM} I think it's necessary to
      mention also ddCOSMO and ddPCM as alternative strategies
      ~\autocite{Cances2013-jg, Lipparini2013-cy, Lipparini2014-to,
      Lipparini2014-fq, Stamm2016-fv}
    \item variational formulation (no derivations, just mention the
      relevant literature)
\end{itemize}

\pagebreak

\section{Continuum Solvation Models: Why and How}\label{sec:CSM-why-how}
\todo[inline]{CURRENTLY VERBATIM FROM MASTER THESIS}

Continuum models arise as limits, in a proper sense, to the discrete
models. To stress this point we introduce the \emph{solution}
Hamiltonian in the Born--Oppenheimer approximation as:
\begin{equation}\label{eq:solution-ham}
 H(\vect{r}_\mathrm{M}, \vect{r}_\mathrm{S}) =
  H_\mathrm{M}(\vect{r}_\mathrm{M}) +  H_\mathrm{S}(\vect{r}_\mathrm{S})
+ H_\mathrm{MS}(\vect{r}_\mathrm{M}, \vect{r}_\mathrm{S})
\end{equation}
where the subscript M refers to the solute while S to the solvent. The
coordinates $(\vect{r}_\mathrm{M}, \vect{r}_\mathrm{S})$ refer to
\emph{both} nuclei and electrons, the interaction term is given by the
usual Coulombic electrostatic Hamiltonian.

It is important to remark that nuclear coordinates must be considered
explicitly. Liquid phases are, by definition, characterized by the high
mobility of their molecular constituents. Changes in the internal
geometry of solvent molecules, triggered by intermolecular interactions
between themselves and with the solute, always play a role in the
solvation process. Whether this role is prominent or not cannot be
decided \emph{a priori}.

From a computational point of view, using the Hamiltonian in Eq.~\eqref{eq:solution-ham} is simply not feasible. We would have to
determine a \acs{PES} of enormous dimensionality and then explore the full
dynamics of the system. Even assuming that the minimum energy
conformation on the \acs{PES} can be fully characterized, its knowledge will
not lead us to a correct description of the physics of solvation. In
fact, macroscopic observables of systems with a large number of degrees
of freedom arise as \emph{average} values of the microscopic behaviour
of every single component, the average being either on the phase space
trajectory or on the appropriate ensemble.~\autocite{Hill1960-ql}. It is always
necessary to perform some kind of average upon the energies
corresponding to all the accessible conformations of the whole
solute+solvent system.

Of course, this formidable task may be accomplished using statistical
thermodynamics and the idea of \emph{statistical ensembles} developed by
Gibbs. To apply the idea of an ensemble average we must resort to a
molecular dynamics or Monte Carlo simulation of the solution, in order
to obtain the appropriate partition function, $Z$. This introduces a
number of points that will be central in the development of continuum
models:
\begin{enumerate}
 \item statistical simulations rely on \emph{macroscopic} parameters
   such as the temperature or the density. These parameters are not
   present in the Hamiltonian \eqref{eq:solution-ham}, but are necessary
   for the description of molecular systems in the condensed phase. This
   is true whether one considers discrete or continuum approaches;
 \item the basic energetic quantity is the thermodynamic potential
   characterizing the chosen ensemble. If a direct comparison with the
   experiment is sought, one should run a simulation in the $(NpT)$
   ensemble whose potential is the Gibbs free energy $G$. This point is
   of paramount importance in continuum models and we will have the
   opportunity to stress it in this Chapter as well as in Chapter
   \ref{chap:relpcmscf};
 \item even starting from a completely atomistic point of view, our
   final results will always be in the form of an average over solvent
   conformations. We have explicitly replaced a discrete description
   with a continuous distribution function. Atomistic details can of
   course be recovered by further analysis, but the point remains:
   properties of solutions (the solvation energy among them) have an
   intrinsic average nature.
\end{enumerate}

The fact that an averaging procedure is essential in studying solvation
processes should convince the reader that, at least from a purely
mathematical point of view, we can replace the full Hamiltonian
\eqref{eq:solution-ham} with an \emph{effective} Hamiltonian, averaging
the solvent degrees of freedom in a preliminary
step.~\autocite{Angyan1992-vo, Tapia1992-pu}
\todo[inline]{Some pieces missing here, FILL IN}
Alternatively, an approximate decoupling can be obtained replacing the
mean-field operator in Eq.~\eqref{eq:ave1} by its classical average over
a suitable ensemble:
\begin{equation}\label{eq:ave_classic}
 \Braket{H_\mathrm{MS}}_\mathrm{S} = \frac{\int\diff\Gamma H_\mathrm{MS}\exp
\left(-\beta H_\mathrm{S}\right)}{\int\diff\Gamma\exp\left(-\beta H_\mathrm{S}\right)}.
\end{equation}
This classical average can be written in terms of the $g(\vect{r})$ distribution functions. These functions are defined
for the electrons and the nuclei of the solvent with respect to the fixed frame of reference of the solute molecule, see \noparcite[ref.][]{hansen}.
This amounts to considering the solvent as a structureless continuum, hence defining continuum models.

Continuum models are then characterized, by a solute-only
\emph{effective} Hamiltonian:\footnote{We will use the symbol
$H_\mathrm{MS}$ for the interaction Hamiltonian even if it is not the
full interaction term of Eq.~\eqref{eq:solution-ham}.}
\begin{equation}\label{eq:effective-ham}
 H(\vect{r}_\mathrm{M}) = H_\mathrm{M}(\vect{r}_\mathrm{M})
+ H_\mathrm{MS}(\vect{r}_\mathrm{M}),
\end{equation}
the explicit form of the averaged interaction in
Eq.~\eqref{eq:effective-ham} is in terms of solvent \emph{response
functions}, $Q_x(\vect{r},\vect{r}^\prime)$.
As will be apparent in the following, this term may depend on the solute
density, making the effective Hamiltonian \emph{nonlinear}.

An hierarchy of approximations for the resolution of the effective
Schr\"odinger equation can be devised, as was done for the discrete
models. The distinguishing feature is now the \emph{order} of the
solvent response functions used in the definition of the interaction
term.

If we limit ourselves to a linear response of the solvent we obtain the
class of models commonly called continuum solvation models, the
Polarizable Continuum Model among them. Computer simulations can be used
to determine these functions, but almost always one uses bulk properties
of the pure solvent obtained from experiment.

This, at first sight, crude approximation is rather well justified by
the following argument: from a physical point of view, our solution is
extremely dilute. The presence of the solute is an extremely small
perturbation for the bulk of the solvent and it is safe to assume that
the macroscopic properties of the solution are not far from those of the
pure solvent. Furthermore, the use of macroscopic experimental values
implicitly takes into account the averaging procedure one would carry
out in atomistic simulations of the solution.

As pictorially represented in Figure \ref{fig:discretetocontinuum} the
solvent is now a \emph{structureless polarizable} continuum and the
solute is accommodated inside a cavity formed in this continuum.
\begin{figure}[!h]
 \centering
\includegraphics[width=.5\textwidth]{discretetocontinuum}
\caption{Pictorial representation of the transition from a discrete to a
continuum model of a solution.}
\label{fig:discretetocontinuum}
\end{figure}


\section{Continuum Electrostatics as a Boundary Integral Problem}\label{sec:IEF}

We assume Euclidean space $\mathbb{R}^3$ to be partitioned into two
subdomains $\Omegai$ and $\Omegae$ sharing a boundary
$\Gamma\equiv\partial\Omegai$.
We further assume that $\Omegai$ is a closed domain, entirely contained
inside $\Omegae$. The boundary $\Gamma$ is thus a closed surface, \ie~a
closed 2-manifold in $\mathbb{R}^3$.
The transmission problem is posed as follows:
\todo[inline]{Some consideration on suitable functional spaces and the metric thereof.}
\begin{subequations}\label{eq:transmission}
  \begin{align}[left={\empheqlbrace}]
  \Li u &= f_\mathrm{i} \,\, \text{in}\,\, \Omegai \label{eq:internal} \\
  \Le u &= f_\mathrm{e} \,\, \text{in}\,\, \Omegae \label{eq:external} \\
  [u] &= \ue - \ui = g_\mathrm{D} \,\, \text{on}\,\, \Gamma
  \label{eq:trace-jump} \\
[\partial_L u] &= \partiale u - \partiali u = g_\mathrm{N} \,\,
\text{on}\,\, \Gamma \label{eq:conormal-jump} \\
|u| &\leq C \|x \|^{-1} \,\,\text{for}\,\,\| x \|\rightarrow\infty
\label{eq:radiation}
\end{align}
\end{subequations}
where the jump conditions (eqs. \eqref{eq:trace-jump} and
\eqref{eq:conormal-jump}) are given in terms of Dirichlet and Neumann
data for the solution $u$. The jump conditions are expressed in terms of
trace operators for the solution $u$ and its conormal derivative. For
notational simplicity, will use the symbols $\partiale$ and $\partiali$
for the latter and only give it in explicit form when needed.
Further mathematical details and technical results on the definition of
function traces and their use in setting up the proper normal and
conormal derivatives can be found in the excellent book by
\citeauthor{Sauter2011-an}.~\autocite{Sauter2011-an}.
The
fundamental solutions, or Green's functions, for the elliptic
differential operators $\Li$ and $\Le$ will be denoted by $\Gi$ and
$\Ge$, respectively.

We introduce the relevant boundary integral operators for the
abovementioned transmission problem. They are three of the four
components of the Calder\'on projector.
For $v \in L^2(\Gamma)$, $x, y \in \Gamma$:
\footnote{We can assume a less restrictive functional space, \ie a
Sobolev space of fractional order.}
\begin{equation}
\begin{aligned}
(\bi{S}_\star v)(x) &= \int_\Gamma G_\star(x, y)v(y)\diff y \\
(\bi{D}_\star v)(x) &= \int_\Gamma \partial_{L_\star,y}G_\star(x, y)v(y)\diff y \\
(\bi{D}^\dagger_\star v)(x) &= \int_\Gamma \partial_{L_\star,x}G_\star(x, y)v(y)\diff y \\
\end{aligned}
\end{equation}
where $\star$ is a placeholder for the $\mathrm{i}$ or $\mathrm{e}$ subscript.

\begin{lemma}[Properties of the boundary integral operators]
  The integral operators introduced above enjoy the following
  properties~\autocite{Hsiao2008-xb, Sauter2011-an}:
  \begin{enumerate}
      \item on $L^2(\Gamma)$ $\bi{S}_\star$ is self-adjoint,
        $\bi{D}^\dagger_\star$ is the adjoint operator of
        $\bi{D}_\star$.
      \item The commutation relations:
        \begin{alignat}{2}
          \bi{D}_\star\bi{S}_\star = \bi{S}_\star\bi{D}^\dagger_\star, \quad&
          \bi{S}_\star\bi{D}_\star = \bi{D}^\dagger_\star\bi{S}_\star
        \end{alignat}
        hold
      \item The operators:
        \begin{subequations}
          \begin{align}
   \bi{S}_\star &: H^{-\frac{1}{2}}(\Gamma) \rightarrow H^{\frac{1}{2}}(\Gamma) \\
   \bi{D}_\star &: H^{\frac{1}{2}}(\Gamma) \rightarrow H^{\frac{1}{2}}(\Gamma) \\
   \bi{D}^\dagger_\star &: H^{-\frac{1}{2}}(\Gamma) \rightarrow H^{-\frac{1}{2}}(\Gamma)
          \end{align}
        \end{subequations}
      \item The operator $\bi{S}_\star$ is coervice and admits a
        continuous inverse in the aforementioned Sobolev spaces.
      \item The operators $\lambda - \bi{D}_\star$ and $\lambda -
        \bi{D}^\dagger_\star$ with $\lambda \in (-2\pi, +\infty)$
        admit a continuous inverse in the aforementioned
        Sobolev spaces.
  \end{enumerate}
\end{lemma}

\subsection{Lemma of Integral Representation}
For the transmission problem \ref{eq:transmission} there holds:
\begin{itemize}
\item $\forall x \in \Omegai$
\begin{equation}
u = \bi{S}_\mathrm{i}(\partiali u)
- \bi{D}_\mathrm{i}(\ui) + \int_{\Omegai} \Gi f_\mathrm{i}\diff y
\end{equation}
\item $\forall x \in \Omegae$
\begin{equation}
u = -\bi{S}_\mathrm{e}(\partiale u)
+ \bi{D}_\mathrm{e}(\ue) + \int_{\Omegae}\Ge f_\mathrm{e}\diff y
\end{equation}
\item $\forall x \in \Gamma$
  \begin{equation}\label{eq:stat3}
    \frac{1}{2}\ui = \bi{S}_\mathrm{i}(\partiali u)
    - \bi{D}_\mathrm{i}(\ui) + \int_{\Omegai}\Gi f_\mathrm{i}\diff y
  \end{equation}
\item $\forall x \in \Gamma$
  \begin{equation}\label{eq:stat4}
    \frac{1}{2}\ue = -\bi{S}_\mathrm{e}(\partiale u)
    + \bi{D}_\mathrm{e}(\ue) + \int_{\Omegae}\Ge f_\mathrm{e}\diff y
  \end{equation}
\end{itemize}

Note that the figures refer to cases where the dielectric is supposed to
be homogeneous and isotropic. The derivation are, however, general and
do not assume homogeneity and isotropy.
The source charge densities are not assumed to be continuous, the
hypothesis that they are entirely supported in either of the internal or
external subdomains is however made:
\begin{alignat}{2}
  \Supp(\rhoi) \subseteq \Omegai, \quad& \Supp(\rhoe) \subseteq \Omegae
\end{alignat}

\begin{figure}[h!]
  \centering
  \includegraphics[width=.65\textwidth]{IEF}
  \caption{Vacuum Cavity in dielectric with permittivity $\diel_\mathrm{e}>1$.
  Source charge density $\rho_\mathrm{i}$ inside the cavity
  ($\diel_\mathrm{i}=1$). \textcolor{red}{Regular \acs{IEF}}}
  \label{fig:case0}
\end{figure}

This is the regular \acs{IEF} as derived in:~\autocite{Cances1998-og}
\begin{subequations}
\begin{align}
  \nabla^2 u &= \rhoi \,\, \text{in}\,\, \Omegai \\
  \Le u &= 0 \,\, \text{in}\,\, \Omegae \\
  [u] &= \ue - \ui = 0 \,\, \text{on}\,\, \Gamma \\
[\partial_L u] &= \partiale u - \partiali u = 0 \,\,
\text{on}\,\, \Gamma \\
|u| &\leq C \|x \|^{-1} \,\,\text{for}\,\,\| x \|\rightarrow\infty
\end{align}
\end{subequations}

We introduce the following auxiliary potential:
\begin{equation}
  h(x) =
  \begin{cases}
    &\int_{\mathbb{R}^3}\Gi\rhoi(y)\diff y  \quad x \in \Omegai \\
    &\int_{\mathbb{R}^3}\Ge\rhoi(y)\diff y  \quad x \in \Omegae
  \end{cases}
\end{equation}
for which we have:\footnote{This can be checked by applying the
differential operators to the definition of $h$ and then swapping
differentiation and integration.}
\begin{equation}
  \begin{cases}
    \nabla^2 h &= \rhoi \,\, \text{in}\,\, \Omegai \\
    \Le h &= 0 \,\, \text{in}\,\, \Omegae
  \end{cases}
\end{equation}
We then define the \emph{reaction potential} as:
\begin{equation}
  \xi = u - h
\end{equation}
such that:
\begin{subequations}
\begin{align}
  \nabla^2 \xi &= 0 \,\, \text{in}\,\, \Omegai \\
  \Le \xi &= 0 \,\, \text{in}\,\, \Omegae \\
  -[\xi] &= [h] \,\, \text{on}\,\, \Gamma \\
  -[\partial_L \xi] &= [\partial_L h] \,\, \text{on}\,\, \Gamma
\end{align}
\end{subequations}
inside the cavity, the reaction potential can be represented by a
\emph{single layer potential}, \ie by an apparent surface charge (ASC):
\begin{equation}
  \xi_\mathrm{i} = \bi{S}_\mathrm{i}\sigma
\end{equation}

Applying Eqs. \eqref{eq:stat3} and \eqref{eq:stat4} of the Lemma of Integral
Representation to the reaction potential yields:
\begin{align}
  \frac{1}{2}\xi_\mathrm{i} &= \bi{S}_\mathrm{i}(\partiali \xi) -
  \bi{D}_\mathrm{i}(\xi_\mathrm{i}) \\
  -\frac{1}{2}\xi_\mathrm{e} &= \bi{S}_\mathrm{e}(\partiale \xi) -
  \bi{D}_\mathrm{e}(\xi_\mathrm{e})
\end{align}
in both cases the last term, including the integration over the entire
subdomain volume, drops out ($f_\mathrm{i} = 0 = f_\mathrm{e}$).
While use of Eq. \eqref{eq:stat4} on the auxiliary potential $h$ yields:
\begin{equation}
  -\frac{1}{2}h_\mathrm{e} =
  \bi{S}_\mathrm{e}(\partiale h) -
  \bi{D}_\mathrm{e}(h_\mathrm{e})
\end{equation}
Together with the jump conditions one obtains:
\begin{subequations}
  \begin{align}
    &\bi{S}_\mathrm{i}(\partiali \xi) - \bi{D}_\mathrm{i}(\xi_\mathrm{i})
    = \frac{1}{2}\xi_\mathrm{i} \label{eq:first} \\
    &\bi{S}_\mathrm{e}(\partiale \xi) - \bi{D}_\mathrm{e}(\xi_\mathrm{e})
    = -\frac{1}{2}\xi_\mathrm{e} \label{eq:second} \\
  &\bi{S}_\mathrm{e}(\partiale h) - \bi{D}_\mathrm{e}(h_\mathrm{e})
  = -\frac{1}{2}h_\mathrm{e} \label{eq:third} \\
  &\xi_\mathrm{i} - \xi_\mathrm{e} = h_\mathrm{e} - h_\mathrm{i}
  \label{eq:fourth} \\
  &\partiali \xi - \partiale \xi = \partiale h - \partiali h
  \label{eq:fifth}
  \end{align}
\end{subequations}

\begin{enumerate}
  \item Add Eqs. \eqref{eq:second} and \eqref{eq:third}:
    \begin{equation}
    \bi{S}_\mathrm{e}(\partiale \xi + \partiale h) -
    \bi{D}_\mathrm{e}(\xi_\mathrm{e} + h_\mathrm{e})
    = -\frac{1}{2}(\xi_\mathrm{e} + h_\mathrm{e})
    \end{equation}
  \item Exploit Eqs. \eqref{eq:fourth} and \eqref{eq:fifth} to
    eliminate the external traces and conormal derivatives:
    \begin{equation}
      \bi{S}_\mathrm{e}(\partiali \xi) + \left(\frac{1}{2} -
      \bi{D}_\mathrm{e}\right)\xi_\mathrm{i} =
      - \bi{S}_\mathrm{e}(\partiali h) - \left(\frac{1}{2} -
      \bi{D}_\mathrm{e}\right)h_\mathrm{i}
    \end{equation}
  \item Introduce the integral representation of
    $\xi_\mathrm{i}$:
    \begin{equation}
      \bi{S}_\mathrm{e}(\partiali \xi) + \left(\frac{1}{2} -
      \bi{D}_\mathrm{e}\right)\bi{S}_\mathrm{i}\sigma =
      - \bi{S}_\mathrm{e}(\partiali h) - \left(\frac{1}{2} -
      \bi{D}_\mathrm{e}\right)h_\mathrm{i}
    \end{equation}
  \item Reorganize Eq. \eqref{eq:first}, using the commutation
    relation and the integral representation of $\xi_\mathrm{i}$:
    \begin{equation}
    \partiali \xi = \left(\frac{1}{2} + \bi{D}^\dagger_\mathrm{i}\right)\sigma
    \end{equation}
    such that:
    \begin{equation}
      \left[ \bi{S}_\mathrm{e}\left(\frac{1}{2} + \bi{D}^\dagger_\mathrm{i}\right)
      +
      \left(\frac{1}{2} - \bi{D}_\mathrm{e}\right)\bi{S}_\mathrm{i}
      \right]\sigma =
      - \bi{S}_\mathrm{e}(\partiali h) - \left(\frac{1}{2} -
      \bi{D}_\mathrm{e}\right)h_\mathrm{i}
    \end{equation}
  \item Employ the \ac{DtN} map to simplify
    the RHS. The \acs{DtN} map is derived by applying Eq. \eqref{eq:stat3} to
    the Newton potential:
    \begin{equation}
      \phi(x) = (\bi{N}\rhoi)(x) = \int_{\mathbb{R}^3}\Gi\rhoi(y)\diff y
      = \left.h(x)\right|_{\Omegai}
    \end{equation}
    which is equal, in $\Omegai$, to the auxiliary potential $h(x)$.
    With this definition one has:
    \begin{equation}
      \frac{1}{2}\phi_\mathrm{i} =
      \bi{S}_\mathrm{i}(\partiali \phi) -
      \bi{D}_\mathrm{i}(\phi_\mathrm{i}) + \int_{\Omegai}\Gi\rhoi(y)\diff y
      =
      \bi{S}_\mathrm{i}(\partiali \phi) -
      \bi{D}_\mathrm{i}(\phi_\mathrm{i}) + \phi_\mathrm{i}
    \end{equation}
    eventually leading to the \acs{DtN} map:
    \begin{equation}\label{eq:regular-DtN}
      \left(\frac{1}{2} - \bi{D}_\mathrm{i}\right)\phi_\mathrm{i}
      +\bi{S}_\mathrm{i}(\partiali \phi) = 0
    \end{equation}
  \item Having identified $\phi_\mathrm{i} \equiv h_\mathrm{i}$
    and $\partiali \phi \equiv \partiali h$ and employing the \acs{DtN} map,
    Eq.\eqref{eq:regular-DtN}, one obtains the \acs{IEF}-\acs{PCM} equation:
    \begin{equation}\label{eq:full-IEF}
      \left[ \bi{S}_\mathrm{e}\left(\frac{1}{2} + \bi{D}^\dagger_\mathrm{i}\right)
      +
      \left(\frac{1}{2} - \bi{D}_\mathrm{e}\right)\bi{S}_\mathrm{i}
      \right]\sigma =
      -\left[\left(\frac{1}{2}-\bi{D}_\mathrm{e}\right)
      -\bi{S}_\mathrm{e}\bi{S}_\mathrm{i}^{-1}
       \left(\frac{1}{2}-\bi{D}_\mathrm{i}\right)
      \right]\phi
    \end{equation}
    where the subscript $\mathrm{i}$ for the Newton potential $\phi$ has
    been dropped, given that it is continuous across the boundary
    $\Gamma$.
\end{enumerate}
The above proves the existence of a representation of the reaction
potential valid \emph{inside} the cavity in terms of an apparent surface
charge density. We do not prove the uniqueness of this solution and
refer the interested reader to the original
paper.~\autocite{Cances1998-og}

In the code, the Green's functions are defined \emph{without} the $4\pi$
factors in the denominator. Instead of $\frac{1}{2}$ as coefficients to
the identity operator, one will then have $2\pi$:
\begin{equation}\label{eq:full-IEF-2pi}
  \left[ \bi{S}_\mathrm{e}\left(2\pi + \bi{D}^\dagger_\mathrm{i}\right)
  +
  \left(2\pi - \bi{D}_\mathrm{e}\right)\bi{S}_\mathrm{i}
  \right]\sigma =
  -\left[\left(2\pi-\bi{D}_\mathrm{e}\right)
  -\bi{S}_\mathrm{e}\bi{S}_\mathrm{i}^{-1}
  \left(2\pi-\bi{D}_\mathrm{i}\right)
  \right]\phi
\end{equation}

From Eq. \eqref{eq:full-IEF-2pi} we can derive the isotropic
\acs{IEF}, the \acs{DPCM} and the \acs{CPCM} (by letting
$\diel\rightarrow\infty$) equations.
For a homogeneous, isotropic dielectric with permittivity $\diel$ the
Green's function outside the cavity is simply given by scaling the one
inside:
\begin{equation}
  \Ge = \frac{1}{\diel|x-y|} = \frac{1}{\diel} \Gi = \frac{1}{|x-y|}
\end{equation}
leading to the boundary integral operators:
\begin{alignat}{2}
  \bi{S}_\mathrm{i} = \diel\bi{S}_\mathrm{e} = \bi{S}, \quad&
  \bi{D}_\mathrm{i} = \bi{D}_\mathrm{e} = \bi{D}
\end{alignat}
Eventually, one has:
\begin{equation}\label{eq:isotropic-IEF}
  \left[ 2\pi \left(\frac{\diel+1}{\diel-1}\right)
  - \bi{D} \right]\bi{S}\sigma
  =
  -\left[2\pi-\bi{D}\right]\phi
\end{equation}

\section{Detour and Teaser: Weak Formulation of Partial Differential Equations}\label{sec:weak}

From the strong to the weak formulation of \acp{PDE}.\autocite{Ern2004-oo}

\begin{itemize}
  \item Poisson's equation with conductor boundary conditions
        % This is COSMO!
        % This equation makes sense iff \Psi \in \mathcal{C}^2_0(C) (at least)
        % \Psi = 0 \quad \forall \vect{r}\in\partial C
        \begin{equation*}
            \nabla^2\Psi = -4\pi\rho
            % Dirichlet boundary conditions for a conductor
          \quad \Psi \in \mathcolor{ForestGreen}{\mathcal{C}^2_0(C)}
        \end{equation*}
  \item Project onto the space of test functions
        % Project onto the space of test functions
        \begin{equation*}
          \left\{
          \begin{aligned}
            &\text{Seek $\Psi\in\mathcolor{ForestGreen}{V_0}$ such that:}\\
            &(\zeta, \nabla^2\Psi) =
            -4\pi(\zeta, \rho) \quad
            \forall
            \zeta\in\mathcolor{BurntOrange}{\mathcal{C}^\infty_0(C)}
          \end{aligned}
          \right.
        \end{equation*}
  \item Use
    $\eta\nabla^2\gamma = \nabla\cdot(\eta\nabla\gamma) - \nabla\eta\cdot\nabla\gamma$
        % The integral of the first term on the RHS vanishes.
        % It can be shown using Gauss' Theorem and the conductor
        % boundary conditions.
        \begin{equation*}
          \left\{
          \begin{aligned}
            &\text{Seek $\Psi \in \mathcolor{ForestGreen}{H_0^1(C)}$ such that:}\\
            &\mathcolor{Red}{(\nabla\zeta, \nabla\Psi)} =
            \mathcolor{Blue}{-4\pi(\zeta, \rho)} \quad
            \forall \zeta\in \mathcolor{BurntOrange}{H_0^1(C)}
          \end{aligned}
          \right.
        \end{equation*}
\end{itemize}
\begin{equation*}
  \Psi\in \mathcolor{BurntOrange}{H_0^1(C)} = \lbrace f : C \rightarrow
  \mathbb{R} | f \in L^2(C), \nabla f \in L^2(C), f = 0 \forall \vect{s}
  \in\partial C \rbrace
\end{equation*}
\begin{equation}
  \left\{
  \begin{aligned}
    &\text{Seek $\Psi \in V$ such that:}\\
    &\forall \zeta \in V \,\,\,\,\,
    \mathcolor{Red}{a(\zeta, \Psi)} = \mathcolor{Blue}{b(\zeta)}
  \end{aligned}
  \right.
  \label{eq:weak}
\end{equation}

% Hadamard well-posedness definition:
% Problem \eqref{eq:weak} is well-posed if it admits one and only
% one solution and the solution is bounded by the initial data, by
% an a priori estimate (see Ern&Guermond, p.82, Def. 2.1)
\begin{defin}[Well-posedness]\label{def:hadamard}
  The weak problem Eq. \eqref{eq:weak} is \emph{well-posed} if it
  admits one and only one solution and the solution is bounded by
  the initial data by an \emph{a priori} estimate.
\end{defin}
\begin{defin}[Continuity]\label{def:continuity}
  A bilinear form on a normed vector space $V$ is \emph{bounded}, or
  \emph{continuous}, if there is a constant $C$ such that
  $\forall u, v \in V$:
  \[
  a(u, v) \leq C\lVert u\rVert\lVert v\rVert
  \]
\end{defin}
\begin{defin}[Coercivity]\label{def:coercivity}
  A bilinear form on a normed vector space $V$ is \emph{coercive},
  or \emph{elliptic}, if there is a constant $\alpha >0$ such that
  $\forall u \in V$:
  \[
  a(u, u) \geq \alpha\lVert u\rVert^2
  \]
\end{defin}
This implies that no eigenvalue of the linear operator associated
to the bilinear form can be zero, hence that the operator is
invertible!!~\autocite{Ern2004-oo}

% Maybe present connection with Steepest Descent and Conjugate
% Gradient?
% Introduce a suitable vector space, equipped with a norm
% derived from a scalar product.
% The solution belongs to such a vector space, which is
% bigger that in the strong formulation (less constraints on
% the regularity of the solution)
\begin{equation}
  \left\{
  \begin{aligned}
    &\text{Seek $\Psi \in V$ such that:}\\
    &\forall \zeta \in V \,\,\,\,\,
    \mathcolor{Red}{a(\zeta, \Psi)} = \mathcolor{Blue}{b(\zeta)}
  \end{aligned}
  \right.
\end{equation}
\begin{lemma}[Lax--Milgram]
  If the bilinear form $a$ is \emph{continous} and \emph{coercive}
  in $V$, then, for any continuous linear form $b$, Problem~\eqref{eq:weak} is
  \emph{well-posed}.
\end{lemma}
\begin{corollary}[Variational property]
  If the bilinear form is \emph{symmetric} and \emph{positive}
  the unique solution to Problem \eqref{eq:weak} is
  the \emph{unique minimum} on $V$ of the functional:
  \[
  \mathcal{F}(\zeta) = \frac{1}{2}a(\zeta, \zeta) - b(\zeta)
  \]
\end{corollary}

Weak formulation of \acs{BIE}s.\autocite{Hsiao2008-xb}


\section{Numerical Approaches to Boundary Integral Equations}\label{sec:BEM}

Approximability, conformity, consistency and asymptotic consistency
of the approximation setting, $\inf$-$\sup$ condition, CÃ©a's Lemma
and generalized $\inf$-$\sup$ condition.~\autocite{Ern2004-oo,
TesiFilippo}
Additional cavity generators
TsLess~\autocite{Pomelli2004-lb}
DefPol~\autocite{Pomelli1998-ob, Pomelli1999-dc}
FIXPVA~\autocite{Su2009-em}
Other discretization schemes
CSC~\autocite{York1999-xy, Scalmani2010-tw}
SWIG~\autocite{Lange2010-jp, Lange2010-qo, Lange2011-eu}

\todo[inline]{CURRENTLY COPIED VERBATIM FROM THE SPHERICAL GREEN'S
FUNCTION PAPER}

The numerical solution of boundary integral equations, such as the
\acs{IEF}-\acs{PCM}
Eqs.~\eqref{eq:full-IEF-2pi}-\eqref{eq:isotropic-IEF}, can be achieved
by the application of the \ac{BEM}.
A discretization of the molecular cavity
boundary is necessary.~\autocite{Pomelli2007-wq}
The discretization of the
molecular surface into finite elements leads to a corresponding
discretization of both the integral operators and the functions in
Eqs.~\eqref{eq:full-IEF-2pi}-\eqref{eq:isotropic-IEF}.

Different strategies are available to perform the
discretization: the \emph{collocation} or the \emph{Galerkin}
approach.~\cite{Hackbusch1995-uq, Ern2004-oo}
The final result is the transformation of
the original integral equation to a system of linear equations whose
dimension relates to the number of finite elements generated by
discretizing the boundary.  For general integral equations and
discretization schemes, a dense system matrix is obtained. Moreover, the
discretization scheme might not, in general, preserve the symmetry
property of the original integral equation.

In this paper we apply the traditional centroid collocation
method~\autocite{Tomasi2005-vm, Pomelli2007-wq} on the cavity boundary
discretization obtained \emph{via} the GePol
algorithm.~\autocite{Pascual-Ahuir1987-uo, Pascual-Ahuir1990-lp,
Pomelli1998-qp, Pomelli2001-sj, Frediani2004-ua, Pomelli2007-wq}
In this algorithm, the cavity is made of interlocking spheres, not all
of them necessarily centered on the atoms. The surface is then
discretized by means of $N_\mathrm{ts}$ small triangles $\Delta_i$ whose
centroid defines the \emph{collocation point}. Once the centroid is
properly defined, functions and operators are discretized by applying a
one-point quadrature rule in the finite element centroid.
The \acs{IEF}-\acs{PCM} equation is thus recast as:
\begin{equation}
  \vect{q}
  =
  \mat{T}^{-1}\mat{R}\vect{v}.
\end{equation}
$\vect{q}$ and $\vect{v}$ are vectors of dimension $N_\mathrm{ts}$
collecting the values of the \acs{ASC} and \ac{MEP}
at the collocation points.
The matrices representing the boundary integral operators are:
\begin{align}
  \mat{T} &=
  \left(2\pi\mat{I} - \mat{D}_\mathrm{e}\mat{A}\right)\mat{S}_\mathrm{i}
  +\mat{S}_\mathrm{e}\left(2\pi\mat{I} +
  \mat{A}\mat{D}_\mathrm{i}^\dagger\right) \\
  \mat{R} &=
  \left(2\pi\mat{I} - \mat{D}_\mathrm{e}\mat{A}\right) -
  \mat{S}_\mathrm{e}\mat{S}^{-1}_\mathrm{i}\left(2\pi\mat{I}-\mat{D}_\mathrm{i}\mat{A}\right)
\end{align}
$\mat{I}$ is the $N_\mathrm{ts}$-dimensional identity matrix while the
other matrices are defined as:
\begin{alignat}{2}
  &\mat{A} = \mathrm{diag}(\cdots\,\, a_i = \mathrm{area}(\Delta_i)\,\, \cdots) \\
  &S_{ii, \mathrm{i}} = k\sqrt{\frac{4\pi}{a_i}}, \quad
  S_{ij, \mathrm{i}} = \frac{1}{|\vect{s}_i-\vect{s}_j|}\quad (i \neq j) \\
  &D_{ii, \mathrm{i}} = -k\sqrt{\frac{\pi}{a_i}}\frac{1}{R_i}, \quad
  D_{ij, \mathrm{i}} =
  \frac{(\vect{s}_i-\vect{s}_j)\cdot\vect{n}_j}{|\vect{s}_i-\vect{s}_j|^3}\quad (i \neq j) \\
  &S_{ii, \mathrm{e}} = \frac{S_{ii, \mathrm{i}}}{C(\vect{s}_i, \vect{s}_i)} +
        G_\mathrm{img}(\vect{s}_i, \vect{s}_i), \quad
  S_{ij, \mathrm{e}} =
  \frac{1}{C(\vect{s}_i, \vect{s}_j)|\vect{s}_i-\vect{s}_j|} +
  G_\mathrm{img}(\vect{s}_i, \vect{s}_j) \quad (i \neq j) \\
  &D_{ii, \mathrm{e}} = \diel(\vect{s}_i)\left[
  \frac{D_{ii, \mathrm{i}}}{C(\vect{s}_i, \vect{s}_i)}
  -S_{ii, \mathrm{i}}
  \frac{\nabla C(\vect{s}_i,
  \vect{s}_i)\cdot\vect{n}_i}{C^2(\vect{s}_i, \vect{s}_i)}
  +
  \nabla G_\mathrm{img}(\vect{s}_i, \vect{s}_i)\cdot\vect{n}_i
  \right] \\
  &D_{ij, \mathrm{e}} =
  \diel(\vect{s}_j)\left[
  \frac{1}{C(\vect{s}_i, \vect{s}_j)}
  \frac{(\vect{s}_i-\vect{s}_j)\cdot\vect{n}_j}{|\vect{s}_i-\vect{s}_j|^3}
  -\frac{\nabla C(\vect{s}_i,
  \vect{s}_j)\cdot\vect{n}_j}{C^2(\vect{s}_i, \vect{s}_j)}
  \frac{1}{|\vect{s}_i-\vect{s}_j|}
  + \nabla G_\mathrm{img}(\vect{s}_i, \vect{s}_j)\cdot\vect{n}_j
  \right]\quad (i \neq j)
\end{alignat}
in terms of the centroids $\vect{s}_i, \vect{s}_j$, the finite elements
areas and their curvatures $R_i$. The factor $k=1.07$ is introduced to achieve a better precision on the diagonal elements~\cite{Tomasi2005}.

\todo[inline]{CURRENTLY COPIED VERBATIM FROM THE WAVELET PAPER}

Boundary integral equations, such as the \acs{IEF}-\acs{PCM}
Eqs.~\eqref{eq:full-IEF-2pi}-\eqref{eq:isotropic-IEF},
can conveniently be solved numerically by the application of the
\ac{BEM}.
Both the integral operators and the functions on which these act are
defined solely on the boundary of the cavity.

The application of the boundary element method requires that the boundary of
the molecular cavity is discretized by a number of suitable finite elements.
The discretization of the boundary leads to a discretization of the integral
operators. This discretization can be carried out by using either the
\emph{collocation} or the \emph{Galerkin}
approach.~\autocite{Hackbusch1995-uq, Ern2004-oo}
In both cases, the integral equation is transformed to a system of
linear equations whose dimension is related to the number of finite
elements used in the discretization of the boundary.
The resulting system matrix is, in general, a dense matrix. The
boundary element method thus suffers from limitations imposed by the
number of matrix elements to be stored and the memory and time
requirements of solving the resulting linear system.

The use of a wavelet basis in the Galerkin approach has been proven
beneficial in this respect.~\autocite{Harbrecht2004-uo, Dahmen2006-pj,
Harbrecht2006-ug}.
The resulting system matrices are quasi-sparse
and can be further reduced to a sparse form by discarding
negligible entries without considerable loss of precision.

The wavelet boundary element method starts by defining
a sequence of hierarchical trial spaces,
spanned by standard finite element ansatz functions:
\begin{equation}
  \{0\} = V_{-1} \subset V_0 \subset V_1 \subset \ldots
  \subset V_J, \qquad V_j = \Span{\phi_{j,k} : k\in \Delta_{j}}.
\end{equation}
Here, $\Delta_j$ is an index set for the
single-scale basis of the space $V_j$. In the wavelet method,
the trial space $V_j$ is split into the direct sum $V_j = V_{j-1}
\oplus W_j$. The resulting complementary space $W_j$ is called the
wavelet space and is not necessarily orthogonal to $V_{j-1}$.
% It suffices the equation $W_j \cap V_{j-1} = \{0\}$,
Recursive splitting of the trial spaces leads to the wavelet
decomposition $V_j = \bigoplus_{l = 0}^{j} W_l$.

The complementary space is spanned by the wavelet basis:
\begin{equation} W_j =
  \Span{\psi_{j,k}: k \in \Delta_{j+1}
\setminus \Delta_{j}}.
\end{equation}
The choice of this basis turns
out to be very convenient, since we can exploit the compression
technique described by \citeauthor{Dahmen2006-pj} to build up the sparse
system matrix in the wavelet basis directly, avoiding the computation of
non-relevant matrix entries.~\autocite{Dahmen2006-pj}
The \emph{a priori} compression is carried out in two steps. In the
first step, contributions from basis functions sufficiently far away
from each other are discarded. In the following, elements of the matrix
where one wavelet is in the smooth part of the other one are ignored.
The number of relevant matrix entries scales proportional to $O(N_J)$ with
$N_J$ the number of degrees of freedom for a refinement of the geometry
up to level $J$.

In order to understand the compression steps, let us introduce some
notation. Let the \emph{convex hull} of the support of the wavelet $\psi_{j,k}$
be:
\begin{equation}
  \Omega_{j,k} = \conv\hull\left(\supp \psi_{j,k}\right).
\end{equation}
Moreover, let the \emph{singular support} of the wavelet $\psi_{j,k}$ be:
\begin{equation}
  \Omega'_{j,k} = \sing\supp\psi_{j,k}
\end{equation}
It contains all the points in the support where the wavelet is not smooth.
The compression steps are then governed by the following set of
equations
\begin{equation}
  \left[A_J\right]_{\left(j,k\right)\left(j',k'\right)} =
  \begin{cases}
    \quad\quad 0 & \dist(\Omega_{j,k}, \Omega_{j',k'}) > B_{j,j'} \text{ and }j,j' \geq 0, \\
    \quad\quad 0 & \dist(\Omega_{j,k}, \Omega_{j',k'}) \lesssim 2^{-\min\left\{j,j'\right\}} \,\text{and} \\
      & \quad \dist(\Omega'_{j,k}, \Omega_{j',k'}) > B'_{j,j'} \text{ if }j' > j \geq 0, \\
      & \quad \dist(\Omega_{j,k}, \Omega'_{j',k'}) > B'_{j,j'} \text{ if }j > j' \geq 0, \\
    \langle A\psi_{j',k'},\psi_{j,k}\rangle, & \text{otherwise}
  \end{cases}
\label{eq:compression}
\end{equation}
where $\dist(\cdot, \cdot)$ denotes the distance, either between
the bounding boxes of the wavelets or between the singular support and the
bounding box. The first and second conditions represent the first and second
compression step, respectively. The parameters $j,j'$ are the
levels of the wavelets under consideration and the
level-dependent cut-off parameters $B_{j,j'}$ and $B'_{j,j'}$ are given
by
\begin{align*}
  B_{j,j'} &= a \max
  \left\{2^{-\min\left\{j,j'\right\}},
  2^{\frac{J\left(2d^\prime-op\right) -
  \left(j+j'\right)\left(d^\prime+\tilde{d}\right)}{\left(2\tilde{d}+op\right)}}\right\}
  \text{ and }\\ B'_{j,j'} &= a \max
  \left\{2^{-\min\left\{j,j'\right\}},
  2^{\frac{J\left(2d^\prime-op\right) -
\left(j+j'\right)d^\prime-\max\left\{j,j'\right\}\tilde{d}}{\left(\tilde{d}+op\right)}}\right\}
\end{align*}
with $op$ being the order of the integral operator under consideration.
For the first kind integral equation $op = -1$, while $op = 0$ for the second
kind integral equation. The integer $\tilde{d}$ is related to the vanishing
moments of the wavelet basis:
\begin{equation}
  \int \diff\vect{x}\,\,\vect{x}^r \psi_{j,k}(\vect{x}) = 0,
\quad r = 0, \ldots \tilde{d}-1
\end{equation}
In the particular implementation, $\tilde{d}=3$ for the piecewise
constant wavelet basis,  while $\tilde{d}=4$ for the piecewise bilinear
parametrization.~\autocite{Harbrecht2013-hb}
The compression can thus be adjusted by the parameters $a$ and
$d^\prime$:
\begin{equation}\label{eq:param}
  a \geq 1, \quad d < d^\prime < \tilde{d} + op
\end{equation}
where $d$ is the approximation order of the trial spaces $V_j$:
$d=1, 2$ for piecewise constant and
piecewise bilinear ansatz functions, respectively.
Note that, if the interaction between two wavelets, $\psi_{j,k}$ and $\psi_{j',k'}$, on
level $j$ and $j'$ is neglected in the system matrix, all other
interactions between wavelets resulting from the refinement of
$\psi_{j,k}$ and $\psi_{j',k'}$ can also be ignored. Thus, the
compression pattern of the system matrix is calculated
hierarchically starting from the coarsest level.

Once the compressed system matrix is assembled, we arrive at a sparse
system matrix in the wavelet basis which can be compressed further by
leaving out the sufficiently small elements. This post-processing step
is governed by the rule
\begin{equation}
  \left[A_J\right]_{\left(j,k\right)\left(j',k'\right)}
  \begin{cases}
    \quad\quad 0 & \text{if } |\left[ A_J \right]_{\left(j,k\right)\left(j',k'\right)}| \leq \epsilon_{j,j'}\\
    \left[A_J\right]_{\left(j,k\right)\left(j',k'\right)}, & \text{otherwise,}
  \end{cases}
  \label{eq:aposteriori}
\end{equation}
where the coefficients $\epsilon_{j,j'}$ are given by
\begin{equation}
%\epsilon_{j,j'} = b\min \left\{2^{-|j-j'|}, 2^{-\left(2J-\left(j+j'\right)\right)\frac{2d^\prime-op}{2\tilde{d}+op}}\right\} 2^{J\,op}2^{-2d^\prime\left(J-\frac{j+j'}{2}\right)},
  \epsilon_{j,j'} = b\min \left\{2^{-|j-j'|}, 2^{-\left(2J-\left(j+j'\right)\right)\frac{2d^\prime-op}{2\tilde{d}+op}}\right\} 2^{-2d^\prime\left(J-\frac{j+j'}{2}\right)}
\end{equation}
with the \emph{a posteriori} compression parameter $b < 1$.

\section[Variational Formulation of Classical Polarizable Models]{
Above and Beyond: Classical Polarizable Models within a Variational Formulation}
\label{sec:variational}

Variational functional for implicit models, \acs{PCM} in this
case:~\autocite{Lipparini2010-be, Lipparini2011-aj, Lipparini2016-mo}
\begin{equation}
 U_\mathrm{PCM} = \frac{1}{2}\scalprod{\sigma}{\PCM\sigma} + \scalprod{\esp}{\sigma}
\end{equation}

Variational functional for explicit models,~\autocite{Lipparini} could be
MMpol~\autocite{Curutchet} or PE~\autocite{Steindal, Kongsted, Olsen} or
FQ~\autocite{Rick1994-mn, Rick1995-wu, Rick1996-om, Lipparini}:
\begin{equation}
  U_\mathrm{MM} = \frac{1}{2}\kappa\MM\kappa + \kappa\zeta
\end{equation}

The PCM equations will be written in the ``complete basis'' meaning that
we will introduce the usual \ac{BEM} discretization
at the very end of the derivation. In other words, we will be working
with the exact integral equation and not with its discretized
counterpart. As a consequence, the apparent surface charge $\sigma$ and
the electrostatic potential $\esp$ will have a \emph{continuous}
dependence on a ``cavity surface'' index $\vect{s}$. Whenever a
charge-potential product is present it is then to be interpreted as the
\emph{surface integral}, i.e. the scalar product in the suitable,
infinite-dimensional vector space on the cavity boundary $\Gamma$. The
following shorthand notation will be adopted:
\begin{equation}
 \sigma\esp = \scalprod{\sigma}{\esp}
\end{equation}

Coupled implicit/explicit polarization energy
functional:~\autocite{Lipparini}
\begin{equation}\label{eq:pcm-mm-functional}
  U_\mathrm{pol} =
   \frac{1}{2}\sigma\PCM\sigma + \sigma\esp
 + \frac{1}{2}\kappa\MM\kappa + \kappa\zeta
 + \sigma\bi{X}\kappa
\end{equation}
where one has:
\begin{equation}
  \sigma\MMPCM\kappa = \kappa\MMPCM^\dagger\sigma
\end{equation}
and $\MMPCM$ is the implicit/explicit interaction kernel. This is
charge/dipole or charge/charge interaction kernel for the MMpol and
\ac{PE} models
or the \ac{FQ} model, respectively.
The global minimum of the convex functional is found by differentiating
it with respect to the variational degrees of freedom, \ie{} the
\acl{ASC} (\acs{ASC}) density $\sigma$ and the classical point
charges/dipoles $\kappa$. This leads to the coupled equations:
\begin{align}
  \PCM\sigma + \esp + \MMPCM\kappa &= 0 \\
  \MM\kappa  + \zeta + \MMPCM^\dagger\sigma &= 0
\end{align}
or in the commonly found matrix form:
\begin{equation}
  \begin{pmatrix}
    \PCM & \MMPCM \\
    \MMPCM^\dagger & \MM
  \end{pmatrix}
  \begin{pmatrix}
   \sigma \\
   \kappa
  \end{pmatrix}
  =
  -
  \begin{pmatrix}
   \esp \\
   \zeta
  \end{pmatrix}
\end{equation}
Finally, let us re-express the equations above in a "supermatrix"
formalism:
\begin{equation}
  U_\mathrm{pol} =
  \frac{1}{2}{}^t\p\V\p + {}^t\p\s
\end{equation}
where:
\begin{alignat}{3}
  \p =
  \begin{pmatrix}
    \sigma \\
    \kappa
  \end{pmatrix},
  \quad&
  \s =
  \begin{pmatrix}
   \esp \\
   \zeta
  \end{pmatrix},
  \quad&
  \V =
  \begin{pmatrix}
    \PCM & \MMPCM \\
    \MMPCM^\dagger & \MM
  \end{pmatrix}
\end{alignat}
and the ${}^t\p$ symbol denotes the transposed supervector $\p$.
The supermatrix form will prove particularly useful in the following
derivations.

\todo[inline]{PUT REFERENCES HERE!!!}
The variational formulation offers a series of advantages.
The classical energy functional:
\begin{equation}
  U_\mathrm{pol} =
   \frac{1}{2}\sigma\PCM\sigma + \sigma\esp
 + \frac{1}{2}\kappa\MM\kappa + \kappa\zeta
 + \sigma\bi{X}\kappa
\end{equation}
renders itself to a straightforward physical interpretation. In the
three bilinear terms, \ie{} the ones mediated by an interaction
operator, we can identify the self-interaction of the classical
polarization with itself, be it purely implicit:
$\frac{1}{2}\sigma\PCM\sigma$, purely explicit
$\frac{1}{2}\kappa\MM\kappa$ or mixed $\sigma\MMPCM\kappa$.
These terms are positive definite and give rise to an unfavorable
contribution, which is counterbalanced by the linear terms. These terms
mediate the interaction between the induced polarization and the
inducing fields: $\esp$ and $\zeta$. While $\esp$ is quite clearly the
\acl{MEP} (\acs{MEP}), $\zeta$ can either be the molecular electric
field (MMpol and \acs{PE} models) or again the \acs{MEP} (\acs{FQ} model).
In any case, both will be determined by the quantum mechanical molecular
charge density and can thus be formulated as expectation values of
one-electron operators. Eventually, this achieves the coupling between
the classical -- $\sigma$ and $\kappa$ -- and
the quantum mechanical variational degrees of freedom.

\todo[inline]{Mention the classical equivalent of the Hellmann--Feynman
theorem and why it is particularly useful in formulating response
theory.}
