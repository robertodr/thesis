% mainfile: ../RobertoDiRemigioPhDThesis.tex
%************************************************
\chapter{Summary of Contributions}\label{ch:contributions-summary}

\epigraph{\textonehalf\,\,research \kern 20pt and \textonehalf \kern 20pt \textgreek{Tέχνη}

          \textonehalf\,\,observation, \kern 22pt \textonehalf \kern 20pt \textgreek{Tέχνη}

          \textonehalf\,\,training, \kern 39pt \textonehalf \kern 20pt \textgreek{Tέχνη}
          }{
  --- \textsc{Ezra Pound}, \textit{Canto LXXXV}}

This final Chapter provides a brief overview of the motivations, results and
conclusions of the papers this thesis is based on.
All publications included in this thesis have involved some programming effort.
In Section \ref{sec:software} I will describe the principles we have
striven to follow in developing our \acrshort{PCM} software library and its
management philosophy.
I will also give some details on the interfaces we have developed to different
quantum chemistry codes.
A shorter version of the material in Section \ref{sec:software} has been
accepted for publication in the proceedings of the \emph{Producing High
Performance and Sustainable Software for Molecular Simulation} workshop
held at the 2015 Supercomputing Conference.~\autocite{SC15}
Sections \ref{sec:relapcm}--\ref{sec:pcmopenrsp} contain very short
summaries of the papers and a list of my contributions.
My coauthors have all read and approved the description of contributions.

\pagebreak

\section{Software}\label{sec:software}

The growing complexity of quantum chemical program packages requires that an
appropriate strategy be devised to implement new features.
Scalability is of paramount importance, but it has become clear that
maintainability and extensibility of the code play an equally important role in
managing software complexity\autocite{Wilson2014-vh, ssi, nsf-s2i2,
netherlands-escience, coderefinery, molssi} and ensuring
scientific reproducibility.~\autocite{Hatton1994-us, Hatton1997-ml,
Hatton1997-bb, Ioannidis2005-aj, Merali2010-uy, Prinz2011-kz}

The idea of a \emph{modular programming paradigm} can be traced back to
the dawn of computer science. \citeauthor{Dijkstra1968-zp}
successfully used it in the development of the THE operating
system in 1968,~\autocite{Dijkstra1968-zp} while
\citeauthor{Parnas1972-im} advocated it as a best practice already in
1972.~\autocite{Parnas1972-im}
Modularity is nothing more than a \emph{divide et impera} strategy
applied to programming and it has been recognized as beneficial in many
other scientific computing contexts.
New features are isolated into libraries that can be accessed by host
programs through a well-defined \gls{API}.

In this paradigm, computational tasks are implemented into separate,
independent and interchangeable modules.
Modules are to be thought as computational black boxes \emph{developed},
\emph{tested}, \emph{packaged} and \emph{distributed} independently of
the particular host program in which they will be used.
A well-defined \gls{API} clearly delimits the boundaries of the functionality
offered, thus forcing a programming style and standardisation of the
functionality, eventually.~\autocite{Reddy2011-sd}

When coupled with \emph{open-source} licensing, modularity is a proper
step towards ensuring reproducibility of results from scientific
simulation software.~\autocite{Gezelter2015-gz, Krylov2015-fs,
Jacob2016-oq}
Open-source development can fully leverage the benefits of widespread,
cloud-based, free, code development services, such as hosted
\acp{DVCS},~\autocite{github, gitlab} continuous
integration,~\autocite{travis-ci, appveyor-ci} code
coverage,~\autocite{coveralls} static and dynamic code
analyses,~\autocite{coverity-scan} nightly regression testing, public
issue tracking, code review and so forth: adoption of a modern code
development workflow is easily within reach.

It is, of course, true that the above mentioned services are not
exclusive prerogatives of open-source projects. However, an open review
process of scientific software can often help to establish
reproducibility, extensibility and sustainability of the software
ecosystem.
Open-source software, modular development of new functionalities and
full-fledged exploitation of \acsp{DVCS} ensure a much larger scientific
impact. Third-parties can easily contribute to the project: by improving
the documentation, by reporting bugs or by actively extending the
codebase with new functionality.

The \acrshort{PCM} is an ideal candidate for the creation of a solvation
\acrshort{API}. Consider for example the schematic representation of a
\acrshort{PCM}-\acrshort{SCF} algorithm given in Figure \ref{fig:algorithm}.
The input to and from the \acrshort{PCM} library is limited and well-defined,
as are the components that host quantum chemistry codes need to
implement.
This provides a natural \acrshort{API} design: the \acrshort{API} functions can be
compared \emph{vis-à-vis} with the working equations derived for the
different quantum chemical methods.

\begin{figure}[tb]
\centering
\scalebox{0.7}{\input{gfx/algorithm.tikz}}
\caption[Modular approach to programming a \acrshort{PCM} functionality into an existing \acrshort{SCF} code.]{
Schematic view of a \acrshort{PCM}-\acrshort{SCF} algorithm. Computations/data in
\textcolor{PMS2229}{blue} are implemented by the \acrshort{PCM} \acrshort{API}.
Computations/data in \textcolor{Green}{green} are implemented by the
host quantum chemistry code.
  }
\label{fig:algorithm}
\end{figure}

The \pcmsolver library was developed to fulfill these requirements and
offer the community an easy-to-use implementation of the \acrshort{PCM}.
\pcmsolver is written in C++ with Fortran, C and Python components.
Architectural and conceptual organization of the code is provided by the
C++ layer. To ensure the largest possible impact, the code is C++03 ISO standard
compliant, with external dependencies kept to a minimum.
Tuples, container algorithms and functional programming tools are not
part of the standard we chose to comply to.
Parts of the Boost C++ libraries are used to alleviate these
shortcomings.~\autocite{boost}
Linear algebra operations are managed through the Eigen C++ template
library.~\autocite{eigen}
The Python layer provides input reading and parsing facilities,
as implemented by the GetKw library .~\autocite{libgetkw}
Cavity construction and discretization is handled either by the Fortan
or by the C layer, depending on which computational \emph{backend} is
needed.
Evaluation of the Green's functions, needed to set up the representation
of the boundary integral operators, leverages \gls{AD}. We use the Taylor library, a template C++
implementation of \acrshort{AD}.~\autocite{Bartholomew-Biggs2000-db, libtaylor}
The adoption of \git as \acrshort{DVCS}, \cmake for cross-platform builds and
automatic documentation deployment on \readthedocs simplify
extensibility of the module and promote third-party contributions to the
code base. Continuous integration and nightly testing offer an
invaluable level of confidence in the code.

Careful usage of the C++ object-oriented paradigm is the key to this
wide spectrum of functionalities. The library is in itself made of
modules, communicating by means of composition at the outermost
level of design.
This is an indispensable feature to achieve frictionless language
mixing.
Library internal classes balance the dynamic polymorphism offered by
inheritance and the static polymorphism offered by template programming.
~\autocite{Alexandrescu2001-bp, Sutter2004-nt, Langr2012-js}
Preeminent use of composition over inheritance keeps the coupling
between different modules as low as possible.~\autocite{Gamma1995-fd}

The library is released under the terms of the
version 3 \gls{LGPL}, a standard open-source license.~\autocite{LGPLv3}
We strongly believe that open-source software is the key to a larger
impact for scientific software and a standard license means lower
thresholds to adoption and third-party contributions.~\autocite{LGPLv3}
The library serves as our development platform for the \acrshort{PCM}.
The interfaces to different quantum chemistry codes allow us to explore
new methodologies, significantly cutting down development times.
Use of our \acrshort{API} \emph{significantly} limits coding effort on the
side of the host: continuum solvation at the \acrshort{SCF} level of theory
can be implemented in the host program almost out-of-the-box.

The library was designed to allow host-\acrshort{API} communication through
\emph{pure} functions, \ie{} free from side-effects.
Such an implementation hinges on the theoretical realization that the
\acrshort{PCM} layer is independent of the \acrshort{AO} or \acrshort{MO} spaces
defined in the quantum chemical layer.
Passing and modifying large data structures, such as the Fock and
density matrices, can be completely avoided.
As schematically depicted in Figure \ref{fig:algorithm},
computation of the \acrshort{ASC} only depends on
the electrostatic potential sampled at the cavity boundary:
\begin{equation}
 \esp(\vect{s}) =
 \sum_A \frac{Z_A}{|\vect{R}_A-\vect{s}|} +  \sum_{\kappa\lambda} D_{\lambda\kappa}
 \left[\int\diff\vect{r}\frac{-\Omega_{\kappa\lambda}(\vect{r})}{|\vect{r}-\vect{s}|}\right],
\end{equation}
which is the contraction of charge attraction integrals with a, possibly
perturbed, density matrix, a task handled by the host program.
Formation of the solvent contribution to the Fock matrix requires the
computation of the scalar product
$\scalprod{\sigma(\vect{s})}{\esp_{\kappa\lambda}(\vect{s})}$
between the \acrshort{ASC} and the charge attraction integral matrix, again
a task easily accomplished by the host program.
As shown in Figure \ref{fig:pcmsolver-scheme}, data transfer between
\pcmsolver and the host is limited to the communication of
$\esp(\vect{s})$ and $\sigma(\vect{s})$ and can be implemented
\emph{without} storing any quantity to disk, avoiding possibly costly
I/O operations.

\begin{figure}[tb]
  \centering
  \scalebox{0.7}{\input{gfx/pcmsolver-scheme.tikz}}
  \caption[Schematic view of the relationship between a host quantum chemistry
  program and the \pcmsolver library.]{
  Schematic view of the relationship between a host quantum chemistry
  program and the \pcmsolver library.
  }
  \label{fig:pcmsolver-scheme}
\end{figure}

The \acrshort{API} is implemented in ISO C99 as a \emph{context-aware} set of
functions.~\autocite{library-ronacher, context-api-example}
Upon initialization of the library, a \emph{context} object containing
the state of the \acrshort{PCM} \acrshort{API} is constructed and a handle to it
(a pointer in C++ parlance) is returned to the host program. Further
transactions between \pcmsolver and the host program proceed through
manipulations of the context object.
\pcmsolver introduces the concept of surface functions:
labelled instances of any quantity defined on the cavity surface.
Bookkeeping of a possibly arbitrary number of such quantities is managed
through a map storing labels and pointers to the contents of the
functions.
Listings \ref{lst:C-host} and \ref{lst:Fortran-host} show how calls to
\pcmsolver \acrshort{API} functions might look like in an actual C or Fortran
program, respectively.

\lstinputlisting[language=C,
                 caption={Relevant calls to \pcmsolver in a C host program.
                 Ellipsis in the functions arguments list stand for omitted parameters.
                 For the full, functional example visit
                 \url{http://pcmsolver.readthedocs.io/en/v1.1.5/users/C-example.html}},
                 label={lst:C-host}
                ]{snippets/C_host.c}

A context-aware \acrshort{API} offers a simple strategy for parallelization.
The host program could spawn contexts on a per-process basis,
limiting ownership and access to a context just to its parent process.
Race conditions are trivially avoided in such a scenario.

\lstinputlisting[language=Fortran,
                 caption={Relevant calls to \pcmsolver in a Fortran host program.
                 Notice the use of the standard Fortan ISO C bindings.
                 Ellipsis in the functions arguments list stand for omitted parameters.
                 For the full, functional example visit
                 \url{http://pcmsolver.readthedocs.io/en/v1.1.5/users/fortran-example.html}},
                 label={lst:Fortran-host}
                 ]{snippets/Fortran_host.F90}

\pcmsolver currently offers an implementation of the traditional collocation
solvers for isotropic media,~\autocite{Tomasi2005-vm}
together with some unique functionalities: the wavelet Galerkin solvers on smooth
molecular surfaces,~\autocite{Weijo2010-hy, Bugeanu2015-tp} the Green’s
functions for spherical diffuse interfaces~\autocite{DiRemigio2016-nn} and
the delayed solvers for real-time \acrlong*{TDSCF}
simulations.~\autocite{Corni2015-pe}

Programming effort in this thesis has not only been directed at the
creation of the \pcmsolver library, but also at interfacing it with a
number of quantum chemistry codes.
The first interface was implemented and released within the \DIRAC code
and is described in Paper I.~\autocite{DIRAC15, DiRemigio2015-ou}.
Interfaces to the \LSDALTON\autocite{LSDALTON16, Aidas2013-rp} and
\DALTON\autocite{LSDALTON16, Aidas2013-rp} codes have followed, as
described in Paper II and Paper V, respectively.~\autocite{Bugeanu2015-tp, pcm-openrsp}
Details about the interface to \ReSpect~\autocite{ReSpect-3.5.0} can be
found in Paper IV.~\autocite{pcm-respect}
Coupling with \psicode~\autocite{Turney2012-de} has allowed us to implement the
\acrshort{PCM}-\acrshort{CC} developments described in this thesis.
Finally, development of an interface with the KOALA code is underway.~\autocite{Hofener2014-ex, Hofener2016-qz}

\section{Continuum solvation in the relativistic regime}\label{sec:relapcm}

Systems containing heavy elements are notoriously challenging for quantum chemistry.
In addition to their significantly large sizes, one has to properly include the
effect of special relativity in the quantum chemical description in order to
achieve at least qualitative agreement with experiment.
Additional complications arise if one needs to also include environment effects.
Continuum models arguably represent a cost-effective strategy to achieve a first
approximation of these effects.
In this paper, we presented the first derivation and implementation of the \acrshort{PCM}
coupled to a \acrshort{SCF} description of the solute in the fully relativistic, four-component
regime.
Our preliminary calculations on the group 16 dihydrides \ce{H2X} (\ce{X} =
\ce{O}, \ce{S}, \ce{Se}, \ce{Te}, \ce{Po}) have shown that the method predicts
a noticeable interplay of relativistic and solvent effects when heavier
elements are involved.
The main point of the paper was, however, the adoption of a fully modular
programming strategy. We showed that it is entirely possible to adopt the same
\acrshort{PCM} code and implementation "checkpoints" across altogether different
problem domains, Fig.~\ref{fig:algorithm}.

As a by-product of the four-component implementation, we were able to obtain and visualize \acrshort{MEP} maps
from four-component \acrshort{SCF} wave functions. These add yet another interpretive tool to the toolbox available
in the four-component relativistic regime.
The interface to \DIRAC was later released in the 2014 and later versions,
providing \acrshort{PCM} capabilities to the software package.

I contributed the theoretical derivation of the quantum/classical polarizable
terms in a four-component \acrshort{SCF} framework, for energies and linear response
properties. I devised the coupling of the four-component program \DIRAC with
\pcmsolver by providing the implementation and testing of:
\begin{enumerate*}[label={\alph*)},font={\color{PMS1797}}]
  \item \acrshort{MEP} integrals for four-component wave functions,
  \item the additional Fock matrix contributions and
  \item the additional terms in the response equations.
\end{enumerate*}
I performed all the calculations and large part of the data analysis
for the results reported in the paper.
Finally, I wrote the first draft of the paper and coordinated editing of
all subsequent versions.

\section{The Wavelet Galerkin Boundary Element Method for PCM}\label{sec:wemlin}

Continuum solvation models are inherently parametrized. Apart from solvent permittivities,
the atomic radii and molecular surface definition play a crucial role
in determining the performance of the models.
However, the numerical accuracy of the \acrshort{BEM} procedure used to numerically solve the
underlying \acrshort{BIE} is a not-so-often studied aspect of these models.
Traditionally, collocation methods have been used, but these require parametrization of some of the necessary surface integrals.
Galerkin methods do not suffer from such a limitation and additionally preserve symmetry of the underlying
boundary integral operators.
The use of biorthogonal wavelet bases as finite elements achieves sparsity in
the \acrshort{BEM} procedure, due to their intrinsically hierarchical structure and
the existence of \emph{a priori} and \emph{a posteriori} matrix compression
estimates.
Thus, wavelet Galerkin \acrshort{BEM} represents a valid alternative to traditional
collocation methods, both to achieve a better computational scaling and to
provide accurate, benchmark results.\autocite{Harbrecht2004-uo,
Harbrecht2006-ug, Dahmen2006-pj}

Already~\citeauthor{Weijo2010-hy} had shown that using \gls{PWC} bases can lead
to superior accuracy and convergence in the calculation of quantum mechanical
molecular solvation energies.
In this work we showed that even faster convergence can be achieved when
\gls{PWL} bases are used instead.
Moreover, the same holds for the calculation of static electric properties.
Notably, the traditional collocation solver cannot guarantee the same accuracy,
even for very large finite element bases. This suggests that, in some cases,
\acrshort{BEM} collocation methodologies might slow down or even prevent the
convergence of the quantum mechanical response equations solvers.

For this paper, I provided template interface and test sets for the cavity
generator\autocite{Harbrecht2009-no, Harbrecht2011-dk} and wavelet Galerkin
\acrshort{BEM} solver\autocite{Harbrecht2004-uo, Harbrecht2006-ug} with \pcmsolver.
These were used to interface with the new C++ implementation of the wavelet
Galerkin solvers of Monica Bugeanu.
I implemented the interface between the \LSDALTON quantum chemistry software
package and the \pcmsolver software library. The interface allows to run \acrshort{HF} and
\acrshort{KS}-\acrshort{DFT} single-point and linear response calculations.
Together with coauthor Krzysztof Mozgawa, I performed the benchmark quantum
chemical calculations presented in the paper.
Finally, I coordinated the editing of all manuscript drafts.
In particular, I wrote the first draft of Sections 2.1 and 2.3.
The first draft of Sections 3 and 4 was co-written with the first author, Monica Bugeanu.
I performed most of the data analysis and produced tables and graphs.

Finally, the interface to \LSDALTON was later released in the 2016 version,
providing \acrshort{PCM} capabilities to the software package.

\section{Non homogeneous environments}\label{sec:spherical}

Continuum solvation models offer a simple route to the treatment of non
homogeneous environments.
The general integral equation formulation is in fact transparent with respect
to the definition of the Green's function for the space portion exterior to the
cavity.
As outlined in Chapter \ref{ch:CSM}, the boundary integral operators in the
\acrshort{IEF} equation:
\begin{equation}
  \left[ \bi{S}_\mathrm{e}\left(2\pi + \bi{D}^\dagger_\mathrm{i}\right)
  +
  \left(2\pi - \bi{D}_\mathrm{e}\right)\bi{S}_\mathrm{i}
  \right]\sigma =
  -\left[\left(2\pi-\bi{D}_\mathrm{e}\right)
  -\bi{S}_\mathrm{e}\bi{S}_\mathrm{i}^{-1}
  \left(2\pi-\bi{D}_\mathrm{i}\right)
  \right]\esp,
  \tag{\ref{eq:full-IEF} from Chapter \ref{ch:CSM}}
\end{equation}
can be set up once the Green's functions $\Gi$ and $\Ge$ are known.~\autocite{Cances1998-og}
\citeauthor{Frediani2004-er} showed that a numerical representation of the
Green's function is sufficient to obtain the boundary integral operators in the
\acrshort{PCM} integral equation.
The authors introduced a numerical integration procedure to calculate the
Green's function for an environment characterized by spatially varying, yet
cilindrically symmetric, permittivity functions: a model for planar diffuse interfaces.

In this work, a similar procedure was introduced to tackle diffuse interfaces
in spherical symmetry.
In contrast to previously existing work, our implementation offers a more robust
treatment of thin interfaces, with a rather generic functional form for the
permittivity profile.
We thoroughly analyzed the necessity for the \emph{a posteriori} removal of the
Coulomb singularity from the computed Green's function and its efficient
implementation.
Interface width and curvature influence the transfer of ions and molecules across
spherically symmetric interfaces and peculiar properties may arise.
In this work, we analyzed both effect on the water-vapor and oil-water transfer
of \ce{Li+}, \ce{Br-}, acetone, \emph{para}-nitroaniline and the L0 dye.
Nonelectrostatic interactions were not included in our implementation, although
they have been proved to be crucial for non homogeneous
environments.~\autocite{Mozgawa2014-ad}
Nevertheless our implementation represents a first significant step in the continuum treatment
of such nontrivial environments.

I contributed the theoretical work for this paper, based on earlier drafts from coauthors
Ville Weijo and Hui Cao. In particular, I derived the separation of
the Coulomb singularity in its final form.
Moreover, I contributed the implementation and testing of the Green's function code.
The interface to the \LSDALTON program package, developed within paper II, was
also used for this paper.
I wrote the first draft of the paper and coordinated all subsequent editing stages.

\section{Relativistic Calculation of EPR and pNMR Parameters in
Solution}\label{sec:pcmepr}

Paper IV is a step further in our exploration of the interplay between
relativistic and solvent effects initiated with Paper I.
Whereas Paper I presented the essential framework for the coupling of
four-component \acrshort{SCF} wave functions with a classical polarizable continuum,
in this paper we explored the calculation of first-order magnetic properties:
\gls{EPR} and \gls{pNMR} parameters.~\autocite{Repisky2010-ls, Malkin2011-nm,
Komorovsky2013-xa, Cherry2016-ij}
The two works are thus complementary since they explore two different classes
of properties and present implementations in two algorithmically different
relativistic quantum chemistry codes.
In the relativistic framework, spin-orbit interactions are included from the
outset in the variational optimization of the wave function.
Hence, \acrshort{EPR} and \acrshort{pNMR} parameters are formulated as expectation
values, by virtue of the Hellmann--Feynman theorem.~\autocite{Konishi2009-zb,
Helgaker2000-tz}
Moreover, the \ReSpect code can exploit the \emph{Kramers unrestricted} formalism,
allowing for spin polarization and thus granting facile access to the computation
of spin-dependent properties.~\autocite{Dyall2007-tu}
The same modular programming strategy was adopted in crafting an interface between the
relativistic four-component code \ReSpect\autocite{ReSpect-3.5.0} and \pcmsolver.

My contributions to this paper include prototyping the interface between the
\pcmsolver library and the \ReSpect quantum chemistry code.
The interface is maintained in collaboration with coauthor Michal Repisky, who also
refined the implementation to achieve better computational performance.
I tested the interface against one-component and four-component results obtained with
the \LSDALTON and \DIRAC codes, respectively.
I helped coauthors Michal Repisky, Stanislav Komorovsky and Peter Hrobarik
with setting up the \acrshort{PCM} calculations described in the paper.
Finally, I provided the first draft for Section 2 of the paper and took part in all editing stages.
The interface to \ReSpect will be released in the next public version of the software
package, providing \acrshort{PCM} and \acrshort{COSMO} capabilities.

\section{Open-ended self-consistent field response theory in
solution}\label{sec:pcmopenrsp}

In recent years, the availability of strong lasers has allowed to
design and carry out experiments where the high-order response of
molecular materials can be routinely probed.
The more intense the light source, the more complicated the interpretation of
the measured signal.
Our group has newly developed an open-ended methodology for the computation of
\acrshort{SCF} response functions~\autocite{Thorvaldsen2008-sg, Ringholm2014-gx} and
their residues.~\autocite{Friese2015-kb}
These developments offer a route towards a synergistic experimental and
theoretical approach to high-order absorption spectroscopies.
Paper V grafts a classical polarizable continuum approach to solvation on top
of the open-ended methodology of \citeauthor{Thorvaldsen2008-sg}.
Still nowadays, continuum models represent a cost-effective methodology for the
approximate inclusion of solvent effects, albeit their known limitations with respect
to specific solute-solvent interactions.

I developed the theoretical framework for the open-ended \acrshort{SCF} formulation
of molecular response properties when a quantum/classical polarizable continuum
Hamiltonian is used.~\autocite{Thorvaldsen2008-sg, Lipparini2010-be}
I provided its implementation within the \DALTON code, by interfacing the
\pcmsolver library and the open-ended \acrshort{SCF} response code of
\citeauthor{Ringholm2014-gx}~\autocite{Ringholm2014-gx, Friese2015-kb}
I performed extensive testing of the code by comparing with previously
published implementations of the \acrshort{PCM}-\acrshort{SCF} response functions within
\DALTON.~\autocite{Cammi2003-qy, Frediani2005-nc, Ferrighi2010-pm}
Together with coauthors Maarten T.~P.~Beerepoot and Yann Cornaton, I carried out
the multiphoton absorption calculations presented in the paper. I contributed
to data collection and data analysis.
I drafted the initial versions of Sections 2 and 3 of the manuscript and coordinated all
editing stages with coauthor Maarten T. P. Beerepoot.
